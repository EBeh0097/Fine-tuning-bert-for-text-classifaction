# Fine-tuning-bert-for-text-classifaction

<h1> </h1>


<h2>Description</h2>
Text classification using DistilBertForSequenceClassification, DistilBertTokenizerFast with target variable being a medical specialty while predcitor is the transcription.

<br />
<h2>Data Source</h2>
### [data is attached as an uploaded file ](med_transcripts)


<h2>Languages </h2>

- <b>Python</b> 


<h2>Environments Used </h2>

- <b>Google Collab</b>

<h2>Results </h2>


<p align="center">
Importing Bert <br/>
<img src="https://i.imgur.com/RZbUXwX.png" height="60%" width="60%" alt="Bert"/>
<br />
<br />

<p align="center">
Dataset <br/>
<img src="https://i.imgur.com/hYEUh70.png" height="60%" width="60%" alt="Dataset"/>
<br />
<br />

 <p align="center">
training config <br/>
<img src="https://i.imgur.com/2uv2mme.png" height="60%" width="60%" alt=Training config"/>

<p align="center">
Evaluation <br/>
<img src="https://i.imgur.com/8qhw6Cu.png" height="60%" width="60%" alt="Evaluation"/>


<br />
<br />
